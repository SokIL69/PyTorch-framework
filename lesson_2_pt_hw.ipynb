{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson_2_pt_hw.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ea670c3752e4929a72bb3dbfc26cb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92ae5685e31b4a4db17bbbc4372aa80d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2de951b9a4e94b0890458c5ad2bd796a",
              "IPY_MODEL_9ddac2eac68c4b25a976d0ccd9843465",
              "IPY_MODEL_a35adbfa9a074ed9b38a550a7731d66e"
            ]
          }
        },
        "92ae5685e31b4a4db17bbbc4372aa80d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2de951b9a4e94b0890458c5ad2bd796a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb4adea0a0854e0caf3b9a1900790b59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6a31a9fa2706461bbd326091b6269516"
          }
        },
        "9ddac2eac68c4b25a976d0ccd9843465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_64a7e4bbc13647e8a4176c0ff606b624",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0c6ccdb0da94702b6ddc75fc8bc6bed"
          }
        },
        "a35adbfa9a074ed9b38a550a7731d66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d5d5d43115c4679b75e156dc41a8418",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [00:02&lt;00:00, 75946268.96it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b71f88052c844a083ddd6bf5b76f351"
          }
        },
        "bb4adea0a0854e0caf3b9a1900790b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6a31a9fa2706461bbd326091b6269516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64a7e4bbc13647e8a4176c0ff606b624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0c6ccdb0da94702b6ddc75fc8bc6bed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d5d5d43115c4679b75e156dc41a8418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b71f88052c844a083ddd6bf5b76f351": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Фреймворк PyTorch для разработки искусственных нейронных сетей\n",
        "# Урок 3. Dataset, Dataloader, BatchNorm, Dropout, Оптимизация"
      ],
      "metadata": {
        "id": "w37RraF5POtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='red'>Практическое задание</font>\n",
        "## Feed-forward сети"
      ],
      "metadata": {
        "id": "kqSRAl3fQo-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Итак, давайте потренируемся тренировать нейронные сети прямого распространения (так как делали на паре).<br>\n",
        "При этом попробуем создать свою функцию активации на одном из слоев\n",
        "\n",
        "1. Сделать необходимые импорты\n",
        "2. Загрузить датасет CIFAR-100 cоздадим dataloader для него.\n",
        "Если не хватает вычислительных ресурсов, то можно вернуться к CIFAR-10.\n",
        "3. Создайте собственную архитектуру!\n",
        "- Можете использовать все, что угодно, но в ограничении на использование линейные слои (пока без сверток)\n",
        "- Добавить ограниченный Leaky_relu, то есть output = max(0.1x, 0.5x). \n",
        "Ваша задача добавить его в архитектуру сети как функцию активации.\n",
        "- Запустить обучение (по аналогии с тем, что делали на паре)"
      ],
      "metadata": {
        "id": "1zLtpq3GgDmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполнил Соковнин ИЛ"
      ],
      "metadata": {
        "id": "sIgRCxJdSbf0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='blue'>1. Сделаем необходимые импорты</font>"
      ],
      "metadata": {
        "id": "Z7IKyJIZPPV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch torchvision"
      ],
      "metadata": {
        "id": "xP6G96psP8jY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "import torchvision"
      ],
      "metadata": {
        "id": "peAcPgSwP8wv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='blue'>2. Загрузим датасет CIFAR-100, сразу же создадим dataloader для него</font>\n",
        "\n",
        "Если вам не хватает вычислительных ресурсов, то можно вернуться к CIFAR-10"
      ],
      "metadata": {
        "id": "LcCK5bARPsMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim"
      ],
      "metadata": {
        "id": "WXQTUrdqP9a_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt ### воспользуемся для отображения изображения"
      ],
      "metadata": {
        "id": "BPSKolPXR5vx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They were collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton.\n",
        "\n",
        "**The CIFAR-10 dataset**<br>\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "**The CIFAR-100 dataset**<br>\n",
        "This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "metadata": {
        "id": "6QQvUEh0bX4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# загружаем CIFAR-100\n",
        "train_dataset = torchvision.datasets.CIFAR100(root='data/',\n",
        "                                             train=True,  \n",
        "                                             transform=transforms.ToTensor(), \n",
        "                                             download=True)\n",
        "\n",
        "\n",
        "image, label = train_dataset[0]  # 0-й рисунок ()\n",
        "print(image.size())\n",
        "print(label)\n",
        "\n",
        "# размерность рисунка 3 * 32 * 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "0ea670c3752e4929a72bb3dbfc26cb7a",
            "92ae5685e31b4a4db17bbbc4372aa80d",
            "2de951b9a4e94b0890458c5ad2bd796a",
            "9ddac2eac68c4b25a976d0ccd9843465",
            "a35adbfa9a074ed9b38a550a7731d66e",
            "bb4adea0a0854e0caf3b9a1900790b59",
            "6a31a9fa2706461bbd326091b6269516",
            "64a7e4bbc13647e8a4176c0ff606b624",
            "d0c6ccdb0da94702b6ddc75fc8bc6bed",
            "8d5d5d43115c4679b75e156dc41a8418",
            "2b71f88052c844a083ddd6bf5b76f351"
          ]
        },
        "id": "ltUfAuWSR6CS",
        "outputId": "7f4ad274-1113-4af6-9e1a-c46bf1bee787"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ea670c3752e4929a72bb3dbfc26cb7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data/\n",
            "torch.Size([3, 32, 32])\n",
            "19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_1XduApYN2l",
        "outputId": "c395f8e3-5f89-4a10-95ac-c1f144b8c394"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 1.0000, 1.0000,  ..., 0.7647, 0.8314, 0.7137],\n",
              "        [1.0000, 0.9961, 0.9961,  ..., 0.6667, 0.6314, 0.5725],\n",
              "        [1.0000, 0.9961, 1.0000,  ..., 0.7412, 0.6510, 0.4745],\n",
              "        ...,\n",
              "        [0.5804, 0.5569, 0.5490,  ..., 0.1176, 0.2549, 0.2980],\n",
              "        [0.4784, 0.4706, 0.4941,  ..., 0.0863, 0.3804, 0.5529],\n",
              "        [0.3412, 0.3451, 0.3961,  ..., 0.1333, 0.4118, 0.5412]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ycfa2tsZgW5l",
        "outputId": "bfa27d31-fe91-45cf-f64d-d48a517c6ef2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
              "        0.9059, 0.6902, 0.9294, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9882,\n",
              "        0.9490, 0.8980, 0.7647, 0.8314, 0.7137])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image[0][0][31]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apCs26ixgagt",
        "outputId": "3c6a2366-cc0d-4ad2-b122-74fe1f7472fe"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7137)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(image.permute(1, 2, 0).numpy())  # image.permute - Convert image to proper dimension PyTorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "POP5nZntP9lm",
        "outputId": "81bec47a-476e-4ae6-ed52-6f1c7246397f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f20dd816490>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=64, \n",
        "                                           shuffle=True)"
      ],
      "metadata": {
        "id": "DbEWsWCcg8sF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4,\n",
        "                                         shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px4Sr_mRZYNG",
        "outputId": "d7090cb2-2340-470b-ee81-57f43fdc537e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### The CIFAR-10 dataset\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "metadata": {
        "id": "yXqisOOIcee0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10 классов\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "k1Ei8BBIZZta"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The CIFAR-100 dataset\n",
        "This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
        "Here is the list of classes in the CIFAR-100:\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ],
      "metadata": {
        "id": "MzmTAUmlcY4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The 100 classes in the CIFAR-100 are grouped into 20 superclasses.\n",
        "# 20 superclasses\n",
        "Superclases = ('aquatic mammals', 'fish', 'flowers', 'food containers',\n",
        "               'fruit and vegetables', 'household electrical devices',\n",
        "               'household furniture', 'insects', 'large carnivores',\n",
        "               'large man-made outdoor things', 'large natural outdoor scenes', \n",
        "               'large omnivores and herbivores', 'medium-sized mammals',\n",
        "               'non-insect invertebrates', 'people', 'reptiles',\n",
        "               'small mammals', 'trees', 'vehicles 1', 'vehicles 2')\n",
        "\n",
        "# 100 classes\n",
        "classes = ('beaver', 'dolphin', 'otter', 'seal', 'whale',\n",
        "           'aquarium fish', 'flatfish', 'ray', 'shark', 'trout',\n",
        "           'orchids', 'poppies', 'roses', 'sunflowers', 'tulips',\n",
        "           'bottles', 'bowls', 'cans', 'cups', 'plates',\n",
        "           'apples', 'mushrooms', 'oranges', 'pears', 'sweet peppers',\n",
        "           'clock', 'computer keyboard', 'lamp', 'telephone', 'television',\n",
        "           'bed', 'chair', 'couch', 'table', 'wardrobe',\n",
        "           'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach',\n",
        "           'bear', 'leopard', 'lion', 'tiger', 'wolf',\n",
        "           'bridge', 'castle', 'house', 'road', 'skyscraper',\n",
        "           'cloud', 'forest', 'mountain', 'plain', 'sea',\n",
        "           'camel', 'cattle', 'chimpanzee', 'elephant', 'kangaroo',\n",
        "           'fox', 'porcupine', 'possum', 'raccoon', 'skunk',\n",
        "           'crab', 'lobster', 'snail', 'spider', 'worm',\n",
        "           'baby', 'boy', 'girl', 'man', 'woman',\n",
        "           'crocodile', 'dinosaur', 'lizard', 'snake', 'turtle',\n",
        "           'hamster', 'mouse', 'rabbit', 'shrew', 'squirrel',\n",
        "           'maple', 'oak', 'palm', 'pine', 'willow',\n",
        "           'bicycle', 'bus', 'motorcycle', 'pickup truck', 'train',\n",
        "           'lawn-mower', 'rocket', 'streetcar', 'tank', 'tractor')"
      ],
      "metadata": {
        "id": "IcoaRwp-cn0o"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Суперклассы = <br>\n",
        "('водные млекопитающие', 'рыба', 'цветы',<br> 'контейнеры для пищевых продуктов',\n",
        "'фрукты и овощи',<br>\n",
        "'бытовые электроприборы',\n",
        "'бытовая мебель',<br>\n",
        "'насекомые', 'большие хищники',<br>\n",
        "'большие искусственные наружные предметы', 'большие естественные сцены на открытом воздухе',<br>\n",
        "'крупные всеядные и травоядные', 'средние млекопитающие',<br>\n",
        "'не насекомое беспозвоночные', 'люди', 'рептилии',\n",
        "'мелкие млекопитающие', 'деревья',<br> 'транспортные средства 1', 'транспортные средства 2')<br><br>\n",
        "\n",
        "Классы =\n",
        "('бобер', 'Дельфин', 'выдра', 'печать', 'кит',<br>\n",
        "'аквариумные рыбки', 'камбала', 'луч', 'акула', 'форель',<br>\n",
        "'орхидеи', 'маки', 'розы', 'подсолнухи', 'тюльпаны',<br>\n",
        "'бутылки', 'шары', 'банок', 'чашки', 'тарелки',<br>\n",
        "'яблоки', 'грибочки', 'апельсины', 'груши', 'сладким перцем',<br>\n",
        "'часы', 'клавиатура', 'светильник', 'телефон', 'телевизор',<br>\n",
        "'постель', 'председатель', 'дивана', 'таблица', 'шкаф',<br>\n",
        "'пчела', 'Жук', 'бабочка', 'гусеница', 'Тараканище',<br>\n",
        "'медведь', 'леопард', 'лев', 'тигр', 'волк',<br>\n",
        "'мост', 'замок', 'дом', 'дорога', 'небоскреб',<br>\n",
        "'облако', 'лесной', 'горный', 'равнина', 'море',<br>\n",
        "'верблюд', 'быдло', 'шимпанзе', 'слон', 'кенгуру',<br>\n",
        "'лиса', 'дикобраз', 'опоссум', 'енот', 'скунс',<br>\n",
        "'краб', 'лобстер', 'улитка', 'паук', 'червь',<br>\n",
        "'ребенок', 'парень', 'девушка', 'мужчина', 'женщина',<br>\n",
        "'крокодил', 'динозавр', 'ящерица', 'змея', 'черепаха',<br>\n",
        "'хомячок', 'Мышь', 'Кролик', 'землеройка', 'белка',<br>\n",
        "'клен', 'дуб', 'ладони', 'сосна', 'Ива',<br>\n",
        "'велосипед', 'автобус', 'мотоцикл', 'пикап', 'поезд',<br>\n",
        "'газонокосилка', 'ракета', 'трамвай', 'танк', 'трактор')"
      ],
      "metadata": {
        "id": "wk85w6XZkl5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lo7TF0KQeFyh"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='blue'>3. Создайте собственную архитектуру!</font>\n",
        "\n",
        "3.1 Можете использовать все, что угодно, но в ограничении на использование линейные слои (пока без сверток)\n",
        "\n",
        "3.2 Давайте добавим ограниченный Leaky_relu, то есть output = max(0.1x, 0.5x)\n",
        "\n",
        "Ваша задача добавить его в архитектуру сети как функцию активации\n",
        "\n",
        "3.4 Запустить обучение (по аналогии с тем, что делали на паре)</font>"
      ],
      "metadata": {
        "id": "kJNuASHoPsjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='red'>a. Вариант 1 (нейросеть из лекции 2)</font>"
      ],
      "metadata": {
        "id": "NPbdr2u4DWDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# У нас задача многоклассовой классификации [torch cross entropy loss]\n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        '''\n",
        "          D init() - делаем необходимые настройки.\n",
        "\n",
        "          input_dim - размерность вектора входных данных\n",
        "          hidden_dim - параметр для настройки скрытых слоёв\n",
        "          output_dim - размерность выходного слоя, равно количеству классов (10 или 100)\n",
        "        '''\n",
        "      \n",
        "        super().__init__()  # вызываем конструктор суперкласса\n",
        "\n",
        "        # Создаём 4 полносвязных слоя (в Pytorch Linear, в Keras они называются Dense )\n",
        "        self.fc1 = nn.Linear(input_dim, 4 * hidden_dim)\n",
        "        self.fc2 = nn.Linear(4 * hidden_dim, 2 * hidden_dim)\n",
        "        self.fc3 = nn.Linear(2 * hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    # Метод forward() - описывает, как данные передаются по сети при обучении,\n",
        "    # так и при предсказании (inference - вывод)\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        1 - Необходимо преобразовать 3-х мерный тензор (x, y + rgb)\n",
        "            в одномерный тензор для передачи в первый слой Linear. \n",
        "            Делается это с помощью view() - аналог reshape().\n",
        "        2 - Возвращаем выходные данные softmax,\n",
        "            чтобы получить прогноз для этого изображения.\n",
        "        '''\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        # Задаём функцию потерь Leaky_relu\n",
        "        x = F.leaky_relu(x, 0.05)\n",
        "        x = self.fc2(x)\n",
        "        x = F.leaky_relu(x, 0.05)\n",
        "        x = self.fc3(x)\n",
        "        x = F.leaky_relu(x, 0.05)\n",
        "        x = self.fc4(x)\n",
        "        # x = F.softmax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        x = self.forward(x)\n",
        "        x = F.softmax(x)\n",
        "        return x      \n",
        "\n",
        "\n",
        "\n",
        "# net = Net(3072, 100, 10)   # CIFAR10\n",
        "net = Net(3072, 100, 100)  # CIFAR10"
      ],
      "metadata": {
        "id": "vzuTTxcAP-Vv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlGQhbmxIfMy",
        "outputId": "b8948c74-d594-49ba-e55c-a3f256025343"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=3072, out_features=400, bias=True)\n",
            "  (fc2): Linear(in_features=400, out_features=200, bias=True)\n",
            "  (fc3): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (fc4): Linear(in_features=100, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запускаем обучение"
      ],
      "metadata": {
        "id": "sVrrJYMACs3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "-96YjghYRf2r"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "lBJ_sqQSe6BE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(10)):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm-paMZoe9Ah",
        "outputId": "6184bc70-a450-44f2-a420-732d5b6cc26b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.002\n",
            "[1,   301] loss: 0.691\n",
            "[1,   601] loss: 0.690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:16<02:32, 16.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,     1] loss: 0.002\n",
            "[2,   301] loss: 0.689\n",
            "[2,   601] loss: 0.688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:33<02:14, 16.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3,     1] loss: 0.002\n",
            "[3,   301] loss: 0.685\n",
            "[3,   601] loss: 0.681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [00:50<01:57, 16.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4,     1] loss: 0.002\n",
            "[4,   301] loss: 0.664\n",
            "[4,   601] loss: 0.647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:07<01:40, 16.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5,     1] loss: 0.002\n",
            "[5,   301] loss: 0.628\n",
            "[5,   601] loss: 0.620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:23<01:23, 16.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6,     1] loss: 0.002\n",
            "[6,   301] loss: 0.611\n",
            "[6,   601] loss: 0.610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [01:40<01:06, 16.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7,     1] loss: 0.002\n",
            "[7,   301] loss: 0.603\n",
            "[7,   601] loss: 0.602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [01:57<00:50, 16.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8,     1] loss: 0.002\n",
            "[8,   301] loss: 0.597\n",
            "[8,   601] loss: 0.594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [02:14<00:33, 16.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9,     1] loss: 0.002\n",
            "[9,   301] loss: 0.592\n",
            "[9,   601] loss: 0.584\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [02:31<00:16, 16.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10,     1] loss: 0.002\n",
            "[10,   301] loss: 0.582\n",
            "[10,   601] loss: 0.577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:47<00:00, 16.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='red'>b. Вариант 2</font>\n",
        "\n",
        "- Увеличиваем количество слоёв и нейронов"
      ],
      "metadata": {
        "id": "85wn2m0uDyuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# У нас задача многоклассовой классификации [torch cross entropy loss]\n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        '''\n",
        "          D init() - делаем необходимые настройки.\n",
        "\n",
        "          input_dim - размерность вектора входных данных\n",
        "          hidden_dim - параметр для настройки скрытых слоёв\n",
        "          output_dim - размерность выходного слоя, равно количеству классов (10 или 100)\n",
        "        '''\n",
        "      \n",
        "        super().__init__()  # вызываем конструктор суперкласса\n",
        "\n",
        "        # Создаём 4 полносвязных слоя (в Pytorch Linear, в Keras они называются Dense )\n",
        "        self.fc1 = nn.Linear(input_dim, 8 * hidden_dim)\n",
        "        self.fc2 = nn.Linear(8 * hidden_dim, 4 * hidden_dim)\n",
        "        self.fc3 = nn.Linear(4 * hidden_dim, 2 * hidden_dim)\n",
        "        self.fc4 = nn.Linear(2 * hidden_dim, hidden_dim)\n",
        "        self.fc5 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    # Метод forward() - описывает, как данные передаются по сети при обучении,\n",
        "    # так и при предсказании (inference - вывод)\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        1 - Необходимо преобразовать 3-х мерный тензор (x, y + rgb)\n",
        "            в одномерный тензор для передачи в первый слой Linear. \n",
        "            Делается это с помощью view() - аналог reshape().\n",
        "        2 - Возвращаем выходные данные softmax,\n",
        "            чтобы получить прогноз для этого изображения.\n",
        "        '''\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        # Задаём функцию потерь Leaky_relu\n",
        "        x = F.leaky_relu(x, 0.05)\n",
        "        x = self.fc2(x)\n",
        "        x = F.leaky_relu(x, 0.05)\n",
        "        x = self.fc3(x)\n",
        "        x = F.leaky_relu(x, 0.05)\n",
        "        x = self.fc4(x)\n",
        "        x = F.leaky_relu(x, 0.05)\n",
        "        x = self.fc5(x)\n",
        "        # x = F.softmax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        x = self.forward(x)\n",
        "        x = F.softmax(x)\n",
        "        return x      \n",
        "\n",
        "\n",
        "\n",
        "# net = Net(3072, 100, 10)   # CIFAR10\n",
        "net = Net(3072, 100, 100)  # CIFAR100\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPoZMMiHe9Xo",
        "outputId": "9bcdbf38-ba95-4a2a-f07b-50c224dfc7f2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=3072, out_features=800, bias=True)\n",
            "  (fc2): Linear(in_features=800, out_features=400, bias=True)\n",
            "  (fc3): Linear(in_features=400, out_features=200, bias=True)\n",
            "  (fc4): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (fc5): Linear(in_features=100, out_features=100, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "7JXEzVHtEB9P"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(10)):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRBUIi01CtvM",
        "outputId": "cf1d242a-0732-4890-ecb5-9d05ffefe150"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.002\n",
            "[1,   301] loss: 0.691\n",
            "[1,   601] loss: 0.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:28<04:18, 28.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,     1] loss: 0.002\n",
            "[2,   301] loss: 0.691\n",
            "[2,   601] loss: 0.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:57<03:48, 28.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3,     1] loss: 0.002\n",
            "[3,   301] loss: 0.690\n",
            "[3,   601] loss: 0.690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [01:26<03:21, 28.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4,     1] loss: 0.002\n",
            "[4,   301] loss: 0.689\n",
            "[4,   601] loss: 0.689\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:54<02:51, 28.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5,     1] loss: 0.002\n",
            "[5,   301] loss: 0.687\n",
            "[5,   601] loss: 0.685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [02:22<02:22, 28.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6,     1] loss: 0.002\n",
            "[6,   301] loss: 0.675\n",
            "[6,   601] loss: 0.661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [02:51<01:53, 28.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7,     1] loss: 0.002\n",
            "[7,   301] loss: 0.638\n",
            "[7,   601] loss: 0.630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [03:19<01:25, 28.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8,     1] loss: 0.002\n",
            "[8,   301] loss: 0.620\n",
            "[8,   601] loss: 0.615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [03:47<00:56, 28.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9,     1] loss: 0.002\n",
            "[9,   301] loss: 0.608\n",
            "[9,   601] loss: 0.607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [04:18<00:29, 29.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10,     1] loss: 0.002\n",
            "[10,   301] loss: 0.603\n",
            "[10,   601] loss: 0.600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [04:48<00:00, 28.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='red'>с. Вариант 3</font>\n",
        "\n",
        "- Увеличиваем количество нейронов"
      ],
      "metadata": {
        "id": "NpNvwL6cK_06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# У нас задача многоклассовой классификации [torch cross entropy loss]\n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html\n",
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        '''\n",
        "          D init() - делаем необходимые настройки.\n",
        "\n",
        "          input_dim - размерность вектора входных данных\n",
        "          hidden_dim - параметр для настройки скрытых слоёв\n",
        "          output_dim - размерность выходного слоя, равно количеству классов (10 или 100)\n",
        "        '''\n",
        "      \n",
        "        super().__init__()  # вызываем конструктор суперкласса\n",
        "\n",
        "        # Создаём 4 полносвязных слоя (в Pytorch Linear, в Keras они называются Dense )\n",
        "        self.fc1 = nn.Linear(input_dim, 16 * hidden_dim)\n",
        "        self.fc2 = nn.Linear(16 * hidden_dim, 8 * hidden_dim)\n",
        "        self.fc3 = nn.Linear(8 * hidden_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    # Метод forward() - описывает, как данные передаются по сети при обучении,\n",
        "    # так и при предсказании (inference - вывод)\n",
        "    def forward(self, x):\n",
        "        '''\n",
        "        1 - Необходимо преобразовать 3-х мерный тензор (x, y + rgb)\n",
        "            в одномерный тензор для передачи в первый слой Linear. \n",
        "            Делается это с помощью view() - аналог reshape().\n",
        "        2 - Возвращаем выходные данные softmax,\n",
        "            чтобы получить прогноз для этого изображения.\n",
        "        '''\n",
        "\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        # Задаём функцию потерь Leaky_relu\n",
        "        x = F.leaky_relu(x, 0.05)\n",
        "        x = self.fc2(x)\n",
        "        x = F.leaky_relu(x, 0.05)\n",
        "        x = self.fc3(x)\n",
        "        x = F.leaky_relu(x, 0.05)\n",
        "        x = self.fc4(x)\n",
        "        # x = F.softmax(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        x = self.forward(x)\n",
        "        x = F.softmax(x)\n",
        "        return x      \n",
        "\n",
        "\n",
        "\n",
        "# net = Net(3072, 100, 10)   # CIFAR10\n",
        "net = Net(3072, 100, 100)  # CIFAR10"
      ],
      "metadata": {
        "id": "kQvfXnFaK7Z2"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "hfcJVuXZK7eF"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(10)):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # выводим статистику о процессе обучения\n",
        "        running_loss += loss.item()\n",
        "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCvhOu3ZK7iL",
        "outputId": "d28d8e9c-922b-431a-e987-08a5d352ae75"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,     1] loss: 0.002\n",
            "[1,   301] loss: 0.691\n",
            "[1,   601] loss: 0.690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:53<07:59, 53.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,     1] loss: 0.002\n",
            "[2,   301] loss: 0.688\n",
            "[2,   601] loss: 0.685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [01:45<07:00, 52.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3,     1] loss: 0.002\n",
            "[3,   301] loss: 0.677\n",
            "[3,   601] loss: 0.665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [02:39<06:14, 53.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4,     1] loss: 0.002\n",
            "[4,   301] loss: 0.636\n",
            "[4,   601] loss: 0.622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [03:35<05:24, 54.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5,     1] loss: 0.002\n",
            "[5,   301] loss: 0.615\n",
            "[5,   601] loss: 0.610\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [04:28<04:29, 53.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6,     1] loss: 0.002\n",
            "[6,   301] loss: 0.607\n",
            "[6,   601] loss: 0.602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [05:21<03:34, 53.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7,     1] loss: 0.002\n",
            "[7,   301] loss: 0.597\n",
            "[7,   601] loss: 0.592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [06:13<02:39, 53.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8,     1] loss: 0.002\n",
            "[8,   301] loss: 0.587\n",
            "[8,   601] loss: 0.583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [07:06<01:46, 53.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9,     1] loss: 0.002\n",
            "[9,   301] loss: 0.575\n",
            "[9,   601] loss: 0.573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [07:59<00:53, 53.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10,     1] loss: 0.002\n",
            "[10,   301] loss: 0.565\n",
            "[10,   601] loss: 0.564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [08:52<00:00, 53.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training is finished!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Вывод__:<br>\n",
        "\n",
        "__Модель 1__:<br>\n",
        "[10,   301] loss: 0.582<br>\n",
        "[10,   601] loss: 0.577<br>\n",
        "100%|██████████| 10/10 [02:47<00:00, 16.79s/it]Training is finished!<br>\n",
        "\n",
        "__Модель 2__:<br>\n",
        "[10,   301] loss: 0.603<br>\n",
        "[10,   601] loss: 0.600<br>\n",
        "100%|██████████| 10/10 [04:48<00:00, 28.80s/it]Training is finished!<br>\n",
        "\n",
        "__Модель 3__:<br>\n",
        "[10,   301] loss: 0.565<br>\n",
        "[10,   601] loss: 0.564<br>\n",
        "100%|██████████| 10/10 [08:52<00:00, 53.29s/it]Training is finished!<br>\n",
        "\n",
        "Лучший результат показала **Модель 3** в которой увеличено количество нейронов по сравнению с **моделью 1**.\n",
        "\n",
        "Второй результат показала базовая **модель 1**.\n",
        "\n",
        "Модель 2 показала результат хуже чем **модель 3** и **модель 1**.\n",
        "\n",
        "Таким образом ***к улучшение модели (в нашем случае) привело увеличение нейронов в слоях нейронной сети***."
      ],
      "metadata": {
        "id": "YVsDM7MJOY__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OnhEEh2hQtsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r8GJaZ7OQtwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Hmviaq0aQtzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_c3FspsHQt_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LINIAR\n",
        "<hr>\n",
        "CLASS torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
        "\n",
        "**Parameters**</br>\n",
        "- **in_features** – size of each input sample\n",
        "- **out_features** – size of each output sample\n",
        "- **bias** – If set to False, the layer will not learn an additive bias. Default: True\n",
        "\n",
        "**Examples**:\n",
        "\n",
        "\\>>> m = nn.Linear(20, 30)<br>\n",
        "\\>>> input = torch.randn(128, 20)<br>\n",
        "\\>>> output = m(input)<br>\n",
        "\\>>> print(output.size())<br>\n",
        "torch.Size([128, 30])\n",
        "\n",
        "_Почему это так_?\n",
        "\n",
        "[128, 30] = [128, 20] * [20, 30]\n",
        "\n",
        "Проще говоря, out = input * (матрица, определяемая nn.Linear ()) + bias\n",
        "(по умолчанию добавлено смещение)\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n"
      ],
      "metadata": {
        "id": "3TgBUiXCQiKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Linear(20, 30)\n",
        "input = torch.randn(128, 20)\n",
        "output = m(input)\n",
        "print(output.size())"
      ],
      "metadata": {
        "id": "f1wy1sW1QAVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "765e9dd6-ce61-4f98-f9ee-bbd352e91805"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input, output, m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiIdgxtkHW5O",
        "outputId": "01754ee5-0c56-4cb7-9644-a6637320c75d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.9445, -0.1955,  0.6603,  ..., -1.8430,  1.0766,  1.1012],\n",
              "         [-0.7275,  0.0465, -0.1388,  ...,  2.5209, -1.3153,  0.2042],\n",
              "         [ 0.2835, -0.1270,  0.3482,  ..., -0.2494,  0.6629,  0.0253],\n",
              "         ...,\n",
              "         [-0.8521, -0.3214, -1.1370,  ...,  1.5775, -0.6483,  1.2110],\n",
              "         [-0.9432, -0.4864, -0.0609,  ...,  0.5493, -0.5672, -0.2799],\n",
              "         [ 0.7819,  0.7470,  0.8465,  ...,  1.1702,  1.1674,  0.2896]]),\n",
              " tensor([[ 1.0652,  0.4712, -0.2064,  ...,  0.7593, -0.0618,  0.2927],\n",
              "         [-0.4639, -0.8240, -0.0374,  ...,  1.4166,  1.2292,  0.8203],\n",
              "         [ 0.5130, -0.1389, -0.2058,  ..., -0.1242,  0.7475,  0.5621],\n",
              "         ...,\n",
              "         [-1.2242, -0.6276, -0.4251,  ..., -0.0405, -0.0474, -0.6426],\n",
              "         [-0.9513,  0.1726,  0.8952,  ..., -0.5510, -0.4159, -0.6513],\n",
              "         [ 0.5482, -0.7059,  0.0225,  ...,  0.0109,  0.6222, -0.2377]],\n",
              "        grad_fn=<AddmmBackward0>),\n",
              " Linear(in_features=20, out_features=30, bias=True))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "emMwvzFJHfTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vBVcarvoK0jI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}