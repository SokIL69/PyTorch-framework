{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фреймворк PyTorch для разработки искусственных нейронных сетей\n",
    "# Урок 8. Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='red'>Практическое задание</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание к уроку 8\n",
    "\n",
    "Переписать загрузку данных с python функций на Dataset и Dataloader и применить сеть с attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнил ___Соковнин ИЛ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "num_samples = 10000\n",
    "data_path = './data/fra-eng/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class eng_fra_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_name=data_path, num_samples=num_samples, nrows=num_samples):\n",
    "        \n",
    "        input_vocab = set()\n",
    "        output_vocab = set()\n",
    "\n",
    "        print(f'Загружаем файл: {file_name}')\n",
    "        df = pd.read_csv(data_path, sep = '\\t', header = None, nrows=num_samples)\n",
    "        df.rename(columns = {0 : 'eng', 1: 'fra'}, inplace = True)\n",
    "        # df = df[['eng', 'fra']]\n",
    "        \n",
    "        input_texts = list(df['eng'])\n",
    "        target_texts = list(df['fra'])\n",
    "        texts = df[['eng','fra']].values.tolist()\n",
    "\n",
    "        for input_text in input_texts:\n",
    "            for word in input_text.split():\n",
    "                input_vocab.add(word.strip())\n",
    "\n",
    "        for target_text in target_texts:\n",
    "            for word in target_text.split():\n",
    "                output_vocab.add(word.strip())\n",
    "\n",
    "        output_vocab = set(list(output_vocab))\n",
    "\n",
    "        input_vocab2index = {word: i+2 for i, word in enumerate(input_vocab)}\n",
    "        output_vocab2index = {word: i+2 for i, word in enumerate(output_vocab)}   \n",
    "        \n",
    "        self.texts = texts\n",
    "        self.input_texts = input_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.input_vocab2index = input_vocab2index\n",
    "        self.output_vocab2index = output_vocab2index\n",
    "        \n",
    "        print('Файл {file_name} загружен')\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_vocab)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "    \n",
    "    def print_ds(self):\n",
    "        for i in self.input_vocab2index:\n",
    "            if self.input_vocab2index[i] < 12:\n",
    "                print(i, self.input_vocab2index[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(sentence, vocab):\n",
    "    return [vocab.get(word.strip(), 0) for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(sentence, vocab):\n",
    "    indexes = indexesFromSentence(sentence, vocab)\n",
    "    indexes.append(1)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromSent(input_sentences, output_sentences, input_vocab2index, output_vocab2index):\n",
    "    input_tensor = tensorFromSentence(input_sentences, input_vocab2index)\n",
    "    target_tensor = tensorFromSentence(output_sentences, output_vocab2index)\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)\n",
    "\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=10):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        #output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=10):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[0]])\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        if decoder_input.item() == 1:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем файл: ./data/fra-eng/fra.txt\n",
      "Файл {file_name} загружен\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hi.', 'Salut !']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = eng_fra_dataset()\n",
    "# ds.print_ds()\n",
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 0%) 8.6540\n",
      "(1 10%) 8.6432\n",
      "(2 20%) 8.7114\n",
      "(3 30%) 8.7780\n",
      "(4 40%) 8.6563\n",
      "(5 50%) 8.6907\n",
      "(6 60%) 8.6709\n",
      "(7 70%) 8.6171\n",
      "(8 80%) 8.7057\n",
      "(9 90%) 8.6936\n",
      "(10 100%) 8.5683\n",
      "(11 110%) 8.5469\n",
      "(12 120%) 8.7139\n",
      "(13 130%) 8.5683\n",
      "(14 140%) 8.5551\n",
      "(15 150%) 8.5791\n",
      "(16 160%) 8.7090\n",
      "(17 170%) 8.6746\n",
      "(18 180%) 8.5785\n",
      "(19 190%) 8.5545\n",
      "(20 200%) 8.5442\n",
      "(21 210%) 8.6220\n",
      "(22 220%) 8.4640\n",
      "(23 229%) 8.4238\n",
      "(24 240%) 8.4129\n",
      "(25 250%) 8.6544\n",
      "(26 260%) 8.5125\n",
      "(27 270%) 8.6281\n",
      "(28 280%) 8.4944\n",
      "(29 290%) 8.5364\n",
      "(30 300%) 4.3646\n",
      "(31 310%) 2.8673\n",
      "(32 320%) 3.4719\n",
      "(33 330%) 5.6825\n",
      "(34 340%) 6.9881\n",
      "(35 350%) 3.6989\n",
      "(36 360%) 5.7402\n",
      "(37 370%) 8.4526\n",
      "(38 380%) 6.3972\n",
      "(39 390%) 2.8499\n",
      "(40 400%) 5.6791\n",
      "(41 409%) 3.5371\n",
      "(42 420%) 6.9641\n",
      "(43 430%) 3.4441\n",
      "(44 440%) 2.9019\n",
      "(45 450%) 3.5218\n",
      "(46 459%) 8.5855\n",
      "(47 470%) 3.4459\n",
      "(48 480%) 3.3896\n",
      "(49 490%) 5.7799\n",
      "(50 500%) 8.3430\n",
      "(51 509%) 4.1402\n",
      "(52 520%) 8.3600\n",
      "(53 530%) 3.4874\n",
      "(54 540%) 3.4993\n",
      "(55 550%) 5.6532\n",
      "(56 560%) 8.3228\n",
      "(57 570%) 8.2857\n",
      "(58 580%) 3.3908\n",
      "(59 590%) 3.4761\n",
      "(60 600%) 2.9122\n",
      "(61 610%) 5.7576\n",
      "(62 620%) 2.1255\n",
      "(63 630%) 2.8752\n",
      "(64 640%) 3.4388\n",
      "(65 650%) 5.7602\n",
      "(66 660%) 2.8140\n",
      "(67 670%) 4.3067\n",
      "(68 680%) 2.7792\n",
      "(69 690%) 4.2024\n",
      "(70 700%) 3.4899\n",
      "(71 710%) 4.3297\n",
      "(72 720%) 4.2798\n",
      "(73 730%) 4.1941\n",
      "(74 740%) 1.7677\n",
      "(75 750%) 3.3655\n",
      "(76 760%) 5.6881\n",
      "(77 770%) 3.4872\n",
      "(78 780%) 2.8212\n",
      "(79 790%) 3.4471\n",
      "(80 800%) 2.8373\n",
      "(81 810%) 2.8392\n",
      "(82 819%) 1.4405\n",
      "(83 830%) 4.3065\n",
      "(84 840%) 3.4888\n",
      "(85 850%) 2.1211\n",
      "(86 860%) 1.7083\n",
      "(87 869%) 5.7449\n",
      "(88 880%) 4.3728\n",
      "(89 890%) 4.3166\n",
      "(90 900%) 5.6929\n",
      "(91 910%) 5.7073\n",
      "(92 919%) 3.3514\n",
      "(93 930%) 4.2191\n",
      "(94 940%) 5.8076\n",
      "(95 950%) 4.3092\n",
      "(96 960%) 3.3367\n",
      "(97 969%) 3.4265\n",
      "(98 980%) 4.1652\n",
      "(99 990%) 4.3131\n",
      "(100 1000%) 3.3042\n",
      "(101 1010%) 4.2407\n",
      "(102 1019%) 4.3077\n",
      "(103 1030%) 4.0787\n",
      "(104 1040%) 3.4712\n",
      "(105 1050%) 6.5220\n",
      "(106 1060%) 5.4730\n",
      "(107 1070%) 4.3562\n",
      "(108 1080%) 3.3208\n",
      "(109 1090%) 3.3962\n",
      "(110 1100%) 2.6828\n",
      "(111 1110%) 3.4143\n",
      "(112 1120%) 5.2917\n",
      "(113 1130%) 3.3450\n",
      "(114 1140%) 4.3646\n",
      "(115 1150%) 8.1083\n",
      "(116 1160%) 3.2043\n",
      "(117 1170%) 8.2521\n",
      "(118 1180%) 3.2850\n",
      "(119 1190%) 6.1555\n",
      "(120 1200%) 4.1405\n",
      "(121 1210%) 3.1853\n",
      "(122 1220%) 8.2854\n",
      "(123 1230%) 3.4270\n",
      "(124 1240%) 5.8434\n",
      "(125 1250%) 3.6965\n",
      "(126 1260%) 5.1788\n",
      "(127 1270%) 6.3482\n",
      "(128 1280%) 5.2209\n",
      "(129 1290%) 4.3987\n",
      "(130 1300%) 2.7631\n",
      "(131 1310%) 4.9685\n",
      "(132 1320%) 6.4926\n",
      "(133 1330%) 6.6403\n",
      "(134 1340%) 2.7461\n",
      "(135 1350%) 6.4476\n",
      "(136 1360%) 6.1024\n",
      "(137 1370%) 2.7978\n",
      "(138 1380%) 6.4351\n",
      "(139 1390%) 4.8719\n",
      "(140 1400%) 6.3706\n",
      "(141 1410%) 5.2169\n",
      "(142 1420%) 5.2958\n",
      "(143 1430%) 8.3757\n",
      "(144 1440%) 3.7746\n",
      "(145 1450%) 5.1228\n",
      "(146 1460%) 6.4771\n",
      "(147 1470%) 6.2795\n",
      "(148 1480%) 8.0541\n",
      "(149 1490%) 4.1945\n",
      "(150 1500%) 3.2948\n",
      "(151 1510%) 3.3078\n",
      "(152 1520%) 3.4067\n",
      "(153 1530%) 3.3969\n",
      "(154 1540%) 4.3285\n",
      "(155 1550%) 4.1467\n",
      "(156 1560%) 2.3881\n",
      "(157 1570%) 6.6833\n",
      "(158 1580%) 4.2498\n",
      "(159 1590%) 5.7011\n",
      "(160 1600%) 6.3458\n",
      "(161 1610%) 8.0959\n",
      "(162 1620%) 6.1270\n",
      "(163 1630%) 4.4043\n",
      "(164 1639%) 5.9884\n",
      "(165 1650%) 6.2670\n",
      "(166 1660%) 5.1088\n",
      "(167 1670%) 7.8307\n",
      "(168 1680%) 4.3583\n",
      "(169 1689%) 5.0198\n",
      "(170 1700%) 2.5263\n",
      "(171 1710%) 2.4644\n",
      "(172 1720%) 3.7579\n",
      "(173 1730%) 3.8781\n",
      "(174 1739%) 5.1875\n",
      "(175 1750%) 5.2423\n",
      "(176 1760%) 6.4581\n",
      "(177 1770%) 6.3770\n",
      "(178 1780%) 4.4186\n",
      "(179 1789%) 8.1706\n",
      "(180 1800%) 5.1959\n",
      "(181 1810%) 6.2181\n",
      "(182 1820%) 5.3593\n",
      "(183 1830%) 6.2772\n",
      "(184 1839%) 3.4379\n",
      "(185 1850%) 5.4718\n",
      "(186 1860%) 5.8691\n",
      "(187 1870%) 4.1194\n",
      "(188 1880%) 5.9407\n",
      "(189 1889%) 6.2854\n",
      "(190 1900%) 4.9510\n",
      "(191 1910%) 4.9567\n",
      "(192 1920%) 7.9553\n",
      "(193 1930%) 6.4501\n",
      "(194 1939%) 5.0072\n",
      "(195 1950%) 7.9465\n",
      "(196 1960%) 4.2768\n",
      "(197 1970%) 7.6960\n",
      "(198 1980%) 5.4163\n",
      "(199 1989%) 2.3627\n",
      "(200 2000%) 3.3014\n",
      "(201 2010%) 2.9093\n",
      "(202 2020%) 4.2868\n",
      "(203 2030%) 5.1238\n",
      "(204 2039%) 3.4426\n",
      "(205 2050%) 3.3029\n",
      "(206 2060%) 3.6530\n",
      "(207 2070%) 6.3795\n",
      "(208 2080%) 8.2970\n",
      "(209 2090%) 4.1029\n",
      "(210 2100%) 3.0094\n",
      "(211 2110%) 2.8075\n",
      "(212 2120%) 5.7466\n",
      "(213 2130%) 6.8209\n",
      "(214 2140%) 4.0509\n",
      "(215 2150%) 6.3899\n",
      "(216 2160%) 6.6765\n",
      "(217 2170%) 4.8609\n",
      "(218 2180%) 5.7061\n",
      "(219 2190%) 2.6665\n",
      "(220 2200%) 4.2997\n",
      "(221 2210%) 4.6779\n",
      "(222 2220%) 7.7399\n",
      "(223 2230%) 3.4904\n",
      "(224 2240%) 5.9524\n",
      "(225 2250%) 3.3732\n",
      "(226 2260%) 6.5530\n",
      "(227 2270%) 6.3897\n",
      "(228 2280%) 4.3997\n",
      "(229 2290%) 6.3131\n",
      "(230 2300%) 6.1737\n",
      "(231 2310%) 5.6638\n",
      "(232 2320%) 6.5595\n",
      "(233 2330%) 4.7846\n",
      "(234 2340%) 6.2470\n",
      "(235 2350%) 5.2470\n",
      "(236 2360%) 5.0243\n",
      "(237 2370%) 4.0766\n",
      "(238 2380%) 4.9771\n",
      "(239 2390%) 4.1620\n",
      "(240 2400%) 4.2752\n",
      "(241 2410%) 6.1546\n",
      "(242 2420%) 8.0127\n",
      "(243 2430%) 7.3944\n",
      "(244 2440%) 3.7852\n",
      "(245 2450%) 5.5639\n",
      "(246 2460%) 5.8070\n",
      "(247 2470%) 4.5081\n",
      "(248 2480%) 3.3177\n",
      "(249 2490%) 6.1424\n",
      "(250 2500%) 4.8769\n",
      "(251 2510%) 5.6767\n",
      "(252 2520%) 6.3313\n",
      "(253 2530%) 5.8503\n",
      "(254 2540%) 5.1131\n",
      "(255 2550%) 6.2380\n",
      "(256 2560%) 6.6334\n",
      "(257 2570%) 4.9057\n",
      "(258 2580%) 7.5600\n",
      "(259 2590%) 6.3421\n",
      "(260 2600%) 6.0600\n",
      "(261 2610%) 5.9970\n",
      "(262 2620%) 7.5013\n",
      "(263 2630%) 2.9166\n",
      "(264 2640%) 4.4993\n",
      "(265 2650%) 6.3387\n",
      "(266 2660%) 7.5894\n",
      "(267 2670%) 4.9674\n",
      "(268 2680%) 4.9916\n",
      "(269 2690%) 7.0191\n",
      "(270 2700%) 3.1235\n",
      "(271 2710%) 6.2449\n",
      "(272 2720%) 4.3063\n",
      "(273 2730%) 3.6311\n",
      "(274 2740%) 5.1241\n",
      "(275 2750%) 4.2560\n",
      "(276 2760%) 6.5261\n",
      "(277 2770%) 6.2576\n",
      "(278 2780%) 7.5537\n",
      "(279 2790%) 6.7295\n",
      "(280 2800%) 3.4686\n",
      "(281 2810%) 4.4341\n",
      "(282 2820%) 4.6484\n",
      "(283 2830%) 4.1926\n",
      "(284 2840%) 5.6641\n",
      "(285 2850%) 7.4276\n",
      "(286 2860%) 6.3403\n",
      "(287 2870%) 4.8021\n",
      "(288 2880%) 6.3185\n",
      "(289 2890%) 6.1308\n",
      "(290 2900%) 4.9397\n",
      "(291 2910%) 6.1703\n",
      "(292 2920%) 5.1116\n",
      "(293 2930%) 5.1514\n",
      "(294 2940%) 7.4930\n",
      "(295 2950%) 6.1430\n",
      "(296 2960%) 5.2488\n",
      "(297 2970%) 6.5583\n",
      "(298 2980%) 6.4585\n",
      "(299 2990%) 2.5360\n",
      "(300 3000%) 7.3432\n",
      "(301 3010%) 5.3094\n",
      "(302 3020%) 4.7731\n",
      "(303 3030%) 3.8094\n",
      "(304 3040%) 6.4413\n",
      "(305 3050%) 4.8452\n",
      "(306 3060%) 4.8443\n",
      "(307 3070%) 6.7259\n",
      "(308 3080%) 5.0113\n",
      "(309 3090%) 4.2529\n",
      "(310 3100%) 5.3686\n",
      "(311 3110%) 3.5010\n",
      "(312 3120%) 7.3298\n",
      "(313 3130%) 3.0126\n",
      "(314 3140%) 5.7961\n",
      "(315 3150%) 4.0713\n",
      "(316 3160%) 4.1895\n",
      "(317 3170%) 4.2154\n",
      "(318 3180%) 3.3621\n",
      "(319 3190%) 3.7719\n",
      "(320 3200%) 3.5461\n",
      "(321 3210%) 3.8672\n",
      "(322 3220%) 2.2592\n",
      "(323 3229%) 4.4236\n",
      "(324 3240%) 4.1651\n",
      "(325 3250%) 4.9972\n",
      "(326 3260%) 6.3210\n",
      "(327 3270%) 5.6646\n",
      "(328 3279%) 3.1966\n",
      "(329 3290%) 1.8386\n",
      "(330 3300%) 6.2228\n",
      "(331 3310%) 2.9484\n",
      "(332 3320%) 2.9042\n",
      "(333 3329%) 6.2112\n",
      "(334 3340%) 5.7372\n",
      "(335 3350%) 2.9380\n",
      "(336 3360%) 2.9884\n",
      "(337 3370%) 6.4366\n",
      "(338 3379%) 4.8631\n",
      "(339 3390%) 2.9941\n",
      "(340 3400%) 5.9566\n",
      "(341 3410%) 6.0075\n",
      "(342 3420%) 2.9243\n",
      "(343 3429%) 4.9600\n",
      "(344 3440%) 6.1358\n",
      "(345 3450%) 4.8024\n",
      "(346 3460%) 6.3665\n",
      "(347 3470%) 4.5617\n",
      "(348 3479%) 5.5599\n",
      "(349 3490%) 5.3879\n",
      "(350 3500%) 2.4614\n",
      "(351 3510%) 5.3554\n",
      "(352 3520%) 4.6011\n",
      "(353 3529%) 6.9401\n",
      "(354 3540%) 6.3419\n",
      "(355 3550%) 5.3728\n",
      "(356 3560%) 7.0425\n",
      "(357 3570%) 2.2512\n",
      "(358 3579%) 2.2133\n",
      "(359 3590%) 4.6224\n",
      "(360 3600%) 4.7654\n",
      "(361 3610%) 3.4882\n",
      "(362 3620%) 6.1286\n",
      "(363 3629%) 3.6462\n",
      "(364 3640%) 3.8383\n",
      "(365 3650%) 3.8151\n",
      "(366 3660%) 5.7941\n",
      "(367 3670%) 2.7073\n",
      "(368 3679%) 4.1310\n",
      "(369 3690%) 5.8564\n",
      "(370 3700%) 4.9188\n",
      "(371 3710%) 3.4872\n",
      "(372 3720%) 2.7547\n",
      "(373 3729%) 4.3752\n",
      "(374 3740%) 4.2608\n",
      "(375 3750%) 2.6504\n",
      "(376 3760%) 4.4365\n",
      "(377 3770%) 4.5438\n",
      "(378 3779%) 4.0117\n",
      "(379 3790%) 3.2426\n",
      "(380 3800%) 2.8025\n",
      "(381 3810%) 2.5820\n",
      "(382 3820%) 4.7871\n",
      "(383 3829%) 2.3473\n",
      "(384 3840%) 3.3660\n",
      "(385 3850%) 4.7917\n",
      "(386 3860%) 6.2630\n",
      "(387 3870%) 2.2825\n",
      "(388 3879%) 5.9082\n",
      "(389 3890%) 6.0612\n",
      "(390 3900%) 6.6363\n",
      "(391 3910%) 6.3408\n",
      "(392 3920%) 3.3637\n",
      "(393 3929%) 2.9790\n",
      "(394 3940%) 1.2784\n",
      "(395 3950%) 4.6737\n",
      "(396 3960%) 4.6312\n",
      "(397 3970%) 4.9905\n",
      "(398 3979%) 4.4991\n",
      "(399 3990%) 2.3875\n",
      "(400 4000%) 5.5885\n",
      "(401 4010%) 5.1912\n",
      "(402 4020%) 5.1969\n",
      "(403 4029%) 3.3273\n",
      "(404 4040%) 3.9910\n",
      "(405 4050%) 2.1268\n",
      "(406 4060%) 6.0192\n",
      "(407 4070%) 5.8745\n",
      "(408 4079%) 6.8655\n",
      "(409 4090%) 2.8233\n",
      "(410 4100%) 4.5174\n",
      "(411 4110%) 4.6348\n",
      "(412 4120%) 5.2043\n",
      "(413 4130%) 5.9632\n",
      "(414 4140%) 3.6224\n",
      "(415 4150%) 3.3544\n",
      "(416 4160%) 4.4811\n",
      "(417 4170%) 7.1022\n",
      "(418 4180%) 2.6919\n",
      "(419 4190%) 3.3021\n",
      "(420 4200%) 6.3905\n",
      "(421 4210%) 5.4008\n",
      "(422 4220%) 6.6378\n",
      "(423 4230%) 6.1315\n",
      "(424 4240%) 6.6388\n",
      "(425 4250%) 4.9089\n",
      "(426 4260%) 6.4351\n",
      "(427 4270%) 5.1482\n",
      "(428 4280%) 3.0260\n",
      "(429 4290%) 4.9495\n",
      "(430 4300%) 3.7016\n",
      "(431 4310%) 6.1299\n",
      "(432 4320%) 4.0895\n",
      "(433 4330%) 3.9902\n",
      "(434 4340%) 5.9496\n",
      "(435 4350%) 5.3130\n",
      "(436 4360%) 4.6522\n",
      "(437 4370%) 5.4032\n",
      "(438 4380%) 4.4384\n",
      "(439 4390%) 5.7474\n",
      "(440 4400%) 4.3345\n",
      "(441 4410%) 2.7817\n",
      "(442 4420%) 4.0884\n",
      "(443 4430%) 3.5009\n",
      "(444 4440%) 2.8396\n",
      "(445 4450%) 4.5937\n",
      "(446 4460%) 3.1118\n",
      "(447 4470%) 3.3859\n",
      "(448 4480%) 2.5290\n",
      "(449 4490%) 1.8920\n",
      "(450 4500%) 5.7369\n",
      "(451 4510%) 1.6092\n",
      "(452 4520%) 6.4466\n",
      "(453 4530%) 7.0454\n",
      "(454 4540%) 5.4016\n",
      "(455 4550%) 6.4004\n",
      "(456 4560%) 5.4915\n",
      "(457 4570%) 4.9020\n",
      "(458 4580%) 2.3821\n",
      "(459 4590%) 6.1554\n",
      "(460 4600%) 6.0630\n",
      "(461 4610%) 6.0515\n",
      "(462 4620%) 2.9704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(463 4630%) 4.3882\n",
      "(464 4640%) 2.5619\n",
      "(465 4650%) 3.1845\n",
      "(466 4660%) 3.5118\n",
      "(467 4670%) 3.7234\n",
      "(468 4680%) 4.5972\n",
      "(469 4690%) 4.2440\n",
      "(470 4700%) 5.6884\n",
      "(471 4710%) 3.2573\n",
      "(472 4720%) 4.5277\n",
      "(473 4730%) 4.7703\n",
      "(474 4740%) 3.5489\n",
      "(475 4750%) 1.6232\n",
      "(476 4760%) 4.6424\n",
      "(477 4770%) 5.2152\n",
      "(478 4780%) 2.1379\n",
      "(479 4790%) 4.4938\n",
      "(480 4800%) 3.1150\n",
      "(481 4810%) 4.2398\n",
      "(482 4820%) 3.1490\n",
      "(483 4830%) 2.7097\n",
      "(484 4840%) 2.2471\n",
      "(485 4850%) 3.2650\n",
      "(486 4860%) 2.9194\n",
      "(487 4870%) 4.7739\n",
      "(488 4880%) 2.2859\n",
      "(489 4890%) 4.3408\n",
      "(490 4900%) 4.5840\n",
      "(491 4910%) 5.3370\n",
      "(492 4920%) 4.5242\n",
      "(493 4930%) 4.1507\n",
      "(494 4940%) 5.4935\n",
      "(495 4950%) 3.4002\n",
      "(496 4960%) 3.6655\n",
      "(497 4970%) 2.0248\n",
      "(498 4980%) 3.8510\n",
      "(499 4990%) 4.2003\n",
      "(500 5000%) 1.5793\n",
      "(501 5010%) 2.1432\n",
      "(502 5020%) 1.8643\n",
      "(503 5030%) 2.7311\n",
      "(504 5040%) 4.2268\n",
      "(505 5050%) 2.7305\n",
      "(506 5060%) 3.2924\n",
      "(507 5070%) 3.4501\n",
      "(508 5080%) 2.6632\n",
      "(509 5090%) 1.7728\n",
      "(510 5100%) 2.4792\n",
      "(511 5110%) 4.5720\n",
      "(512 5120%) 2.8095\n",
      "(513 5130%) 3.0489\n",
      "(514 5140%) 6.3393\n",
      "(515 5150%) 2.4366\n",
      "(516 5160%) 2.4764\n",
      "(517 5170%) 5.1370\n",
      "(518 5180%) 2.4352\n",
      "(519 5190%) 5.5652\n",
      "(520 5200%) 4.5606\n",
      "(521 5210%) 1.2337\n",
      "(522 5220%) 1.3014\n",
      "(523 5230%) 6.1669\n",
      "(524 5240%) 3.3596\n",
      "(525 5250%) 5.6415\n",
      "(526 5260%) 1.6060\n",
      "(527 5270%) 3.2634\n",
      "(528 5280%) 2.7399\n",
      "(529 5290%) 5.1398\n",
      "(530 5300%) 2.7163\n",
      "(531 5310%) 3.0911\n",
      "(532 5320%) 6.0871\n",
      "(533 5330%) 3.7637\n",
      "(534 5340%) 5.8852\n",
      "(535 5350%) 3.2227\n",
      "(536 5360%) 4.0740\n",
      "(537 5370%) 4.2617\n",
      "(538 5380%) 3.2622\n",
      "(539 5390%) 2.3433\n",
      "(540 5400%) 3.5195\n",
      "(541 5410%) 3.3033\n",
      "(542 5420%) 6.1364\n",
      "(543 5430%) 2.7124\n",
      "(544 5440%) 5.1742\n",
      "(545 5450%) 1.5899\n",
      "(546 5460%) 1.7169\n",
      "(547 5470%) 6.0026\n",
      "(548 5480%) 2.8376\n",
      "(549 5490%) 3.4707\n",
      "(550 5500%) 4.2186\n",
      "(551 5510%) 3.3628\n",
      "(552 5520%) 1.8032\n",
      "(553 5530%) 1.4022\n",
      "(554 5540%) 1.5711\n",
      "(555 5550%) 2.3210\n",
      "(556 5560%) 2.4524\n",
      "(557 5570%) 3.4528\n",
      "(558 5580%) 1.3069\n",
      "(559 5590%) 5.9102\n",
      "(560 5600%) 1.9204\n",
      "(561 5610%) 3.1208\n",
      "(562 5620%) 5.6202\n",
      "(563 5630%) 4.2761\n",
      "(564 5640%) 2.7956\n",
      "(565 5650%) 2.7352\n",
      "(566 5660%) 6.7815\n",
      "(567 5670%) 4.2670\n",
      "(568 5680%) 2.3099\n",
      "(569 5690%) 3.4949\n",
      "(570 5700%) 4.5932\n",
      "(571 5710%) 6.2870\n",
      "(572 5720%) 2.3541\n",
      "(573 5730%) 3.0744\n",
      "(574 5740%) 5.6804\n",
      "(575 5750%) 4.2349\n",
      "(576 5760%) 5.3227\n",
      "(577 5770%) 2.0502\n",
      "(578 5780%) 5.7806\n",
      "(579 5790%) 2.0841\n",
      "(580 5800%) 6.0612\n",
      "(581 5810%) 2.4590\n",
      "(582 5820%) 1.0460\n",
      "(583 5830%) 1.3983\n",
      "(584 5840%) 1.9901\n",
      "(585 5850%) 6.1954\n",
      "(586 5860%) 4.3326\n",
      "(587 5870%) 2.7201\n",
      "(588 5880%) 4.2186\n",
      "(589 5890%) 6.2596\n",
      "(590 5900%) 4.6208\n",
      "(591 5910%) 2.6723\n",
      "(592 5920%) 3.0902\n",
      "(593 5930%) 3.9246\n",
      "(594 5940%) 3.9104\n",
      "(595 5950%) 4.5507\n",
      "(596 5960%) 1.4327\n",
      "(597 5970%) 3.6279\n",
      "(598 5980%) 5.5394\n",
      "(599 5990%) 6.5413\n",
      "(600 6000%) 1.9520\n",
      "(601 6010%) 4.2267\n",
      "(602 6020%) 2.8289\n",
      "(603 6030%) 3.4020\n",
      "(604 6040%) 3.7404\n",
      "(605 6050%) 3.2151\n",
      "(606 6060%) 3.7463\n",
      "(607 6070%) 1.8858\n",
      "(608 6080%) 3.8114\n",
      "(609 6090%) 1.5263\n",
      "(610 6100%) 2.0896\n",
      "(611 6110%) 5.0682\n",
      "(612 6120%) 1.4567\n",
      "(613 6130%) 6.0593\n",
      "(614 6140%) 4.5287\n",
      "(615 6150%) 1.3939\n",
      "(616 6160%) 2.1800\n",
      "(617 6170%) 4.7549\n",
      "(618 6180%) 3.3318\n",
      "(619 6190%) 4.5872\n",
      "(620 6200%) 4.2637\n",
      "(621 6210%) 6.2524\n",
      "(622 6220%) 4.5613\n",
      "(623 6230%) 2.3501\n",
      "(624 6240%) 1.0413\n",
      "(625 6250%) 3.9661\n",
      "(626 6260%) 1.3207\n",
      "(627 6270%) 2.2535\n",
      "(628 6280%) 4.2964\n",
      "(629 6290%) 2.2436\n",
      "(630 6300%) 3.6343\n",
      "(631 6310%) 3.0994\n",
      "(632 6320%) 1.9402\n",
      "(633 6330%) 3.4909\n",
      "(634 6340%) 3.2099\n",
      "(635 6350%) 4.0970\n",
      "(636 6360%) 4.1430\n",
      "(637 6370%) 5.9743\n",
      "(638 6380%) 3.7235\n",
      "(639 6390%) 4.3740\n",
      "(640 6400%) 4.1232\n",
      "(641 6409%) 4.1537\n",
      "(642 6420%) 4.1483\n",
      "(643 6430%) 6.1538\n",
      "(644 6440%) 1.8419\n",
      "(645 6450%) 4.0008\n",
      "(646 6459%) 1.6962\n",
      "(647 6470%) 4.4074\n",
      "(648 6480%) 4.1972\n",
      "(649 6490%) 5.6707\n",
      "(650 6500%) 1.8554\n",
      "(651 6509%) 0.7198\n",
      "(652 6520%) 2.0245\n",
      "(653 6530%) 3.7353\n",
      "(654 6540%) 1.7167\n",
      "(655 6550%) 3.1159\n",
      "(656 6559%) 2.4822\n",
      "(657 6570%) 3.9311\n",
      "(658 6580%) 5.3745\n",
      "(659 6590%) 4.0397\n",
      "(660 6600%) 2.5777\n",
      "(661 6609%) 3.6315\n",
      "(662 6620%) 1.1101\n",
      "(663 6630%) 6.4561\n",
      "(664 6640%) 2.7261\n",
      "(665 6650%) 2.1559\n",
      "(666 6659%) 1.3620\n",
      "(667 6670%) 1.9939\n",
      "(668 6680%) 3.3508\n",
      "(669 6690%) 2.2311\n",
      "(670 6700%) 0.9456\n",
      "(671 6709%) 3.0271\n",
      "(672 6720%) 0.8981\n",
      "(673 6730%) 3.2267\n",
      "(674 6740%) 1.6600\n",
      "(675 6750%) 3.1209\n",
      "(676 6759%) 4.6881\n",
      "(677 6770%) 3.8797\n",
      "(678 6780%) 4.4218\n",
      "(679 6790%) 6.8815\n",
      "(680 6800%) 2.1220\n",
      "(681 6809%) 4.9250\n",
      "(682 6820%) 4.5081\n",
      "(683 6830%) 4.2446\n",
      "(684 6840%) 3.1571\n",
      "(685 6850%) 2.8989\n",
      "(686 6859%) 1.7244\n",
      "(687 6870%) 4.2176\n",
      "(688 6880%) 1.9445\n",
      "(689 6890%) 3.1798\n",
      "(690 6900%) 4.2148\n",
      "(691 6909%) 3.2200\n",
      "(692 6920%) 2.3887\n",
      "(693 6930%) 2.2243\n",
      "(694 6940%) 3.1446\n",
      "(695 6950%) 0.9657\n",
      "(696 6959%) 4.0849\n",
      "(697 6970%) 6.1134\n",
      "(698 6980%) 2.2058\n",
      "(699 6990%) 1.1061\n",
      "(700 7000%) 6.7907\n",
      "(701 7009%) 3.6868\n",
      "(702 7020%) 3.7562\n",
      "(703 7030%) 2.4400\n",
      "(704 7040%) 4.7776\n",
      "(705 7050%) 3.5131\n",
      "(706 7059%) 3.6515\n",
      "(707 7070%) 5.6338\n",
      "(708 7080%) 1.1374\n",
      "(709 7090%) 2.1899\n",
      "(710 7100%) 2.8442\n",
      "(711 7109%) 4.5871\n",
      "(712 7120%) 3.8321\n",
      "(713 7130%) 6.8139\n",
      "(714 7140%) 3.8761\n",
      "(715 7150%) 2.2034\n",
      "(716 7159%) 3.3655\n",
      "(717 7170%) 4.4994\n",
      "(718 7180%) 2.1014\n",
      "(719 7190%) 2.6824\n",
      "(720 7200%) 6.3732\n",
      "(721 7209%) 3.4790\n",
      "(722 7220%) 2.7774\n",
      "(723 7230%) 5.5364\n",
      "(724 7240%) 1.1725\n",
      "(725 7250%) 1.1051\n",
      "(726 7259%) 1.8192\n",
      "(727 7270%) 2.6738\n",
      "(728 7280%) 2.9622\n",
      "(729 7290%) 5.2896\n",
      "(730 7300%) 1.2833\n",
      "(731 7309%) 1.1724\n",
      "(732 7320%) 1.2706\n",
      "(733 7330%) 3.8615\n",
      "(734 7340%) 4.3453\n",
      "(735 7350%) 2.5249\n",
      "(736 7359%) 3.3489\n",
      "(737 7370%) 3.9453\n",
      "(738 7380%) 1.7922\n",
      "(739 7390%) 5.8228\n",
      "(740 7400%) 2.6815\n",
      "(741 7409%) 1.2792\n",
      "(742 7420%) 2.1995\n",
      "(743 7430%) 1.7845\n",
      "(744 7440%) 3.8312\n",
      "(745 7450%) 4.2562\n",
      "(746 7459%) 2.4810\n",
      "(747 7470%) 3.5921\n",
      "(748 7480%) 4.2468\n",
      "(749 7490%) 2.8617\n",
      "(750 7500%) 2.0669\n",
      "(751 7509%) 6.4175\n",
      "(752 7520%) 0.8401\n",
      "(753 7530%) 4.4079\n",
      "(754 7540%) 3.5944\n",
      "(755 7550%) 4.5841\n",
      "(756 7559%) 2.9359\n",
      "(757 7570%) 3.1534\n",
      "(758 7580%) 2.5979\n",
      "(759 7590%) 2.4932\n",
      "(760 7600%) 1.9984\n",
      "(761 7609%) 6.1752\n",
      "(762 7620%) 3.3149\n",
      "(763 7630%) 5.7867\n",
      "(764 7640%) 1.1176\n",
      "(765 7650%) 1.6334\n",
      "(766 7659%) 5.7810\n",
      "(767 7670%) 1.8960\n",
      "(768 7680%) 2.3284\n",
      "(769 7690%) 4.4677\n",
      "(770 7700%) 2.8963\n",
      "(771 7709%) 2.4750\n",
      "(772 7720%) 3.9073\n",
      "(773 7730%) 2.0620\n",
      "(774 7740%) 1.0619\n",
      "(775 7750%) 3.8097\n",
      "(776 7759%) 1.3092\n",
      "(777 7770%) 3.3448\n",
      "(778 7780%) 4.5576\n",
      "(779 7790%) 6.5549\n",
      "(780 7800%) 1.0476\n",
      "(781 7809%) 1.7388\n",
      "(782 7820%) 3.2340\n",
      "(783 7830%) 4.2763\n",
      "(784 7840%) 4.2132\n",
      "(785 7850%) 1.2507\n",
      "(786 7859%) 2.9833\n",
      "(787 7870%) 7.1884\n",
      "(788 7880%) 5.4576\n",
      "(789 7890%) 0.9589\n",
      "(790 7900%) 4.4913\n",
      "(791 7909%) 5.3599\n",
      "(792 7920%) 4.0107\n",
      "(793 7930%) 4.7250\n",
      "(794 7940%) 2.9034\n",
      "(795 7950%) 1.1081\n",
      "(796 7959%) 6.0847\n",
      "(797 7970%) 2.5734\n",
      "(798 7980%) 6.2019\n",
      "(799 7990%) 3.5667\n",
      "(800 8000%) 4.9820\n",
      "(801 8009%) 2.0571\n",
      "(802 8020%) 3.0828\n",
      "(803 8030%) 3.5585\n",
      "(804 8040%) 5.0399\n",
      "(805 8050%) 6.4270\n",
      "(806 8059%) 4.5826\n",
      "(807 8070%) 2.4345\n",
      "(808 8080%) 4.3550\n",
      "(809 8090%) 2.1160\n",
      "(810 8100%) 6.1394\n",
      "(811 8109%) 4.1133\n",
      "(812 8120%) 2.1501\n",
      "(813 8130%) 4.5464\n",
      "(814 8140%) 2.2458\n",
      "(815 8150%) 3.1960\n",
      "(816 8159%) 3.1854\n",
      "(817 8170%) 3.3364\n",
      "(818 8180%) 3.7407\n",
      "(819 8190%) 3.0604\n",
      "(820 8200%) 4.2654\n",
      "(821 8210%) 5.4341\n",
      "(822 8220%) 4.4157\n",
      "(823 8230%) 4.4647\n",
      "(824 8240%) 2.6290\n",
      "(825 8250%) 2.8269\n",
      "(826 8260%) 3.1470\n",
      "(827 8270%) 4.8573\n",
      "(828 8280%) 4.6543\n",
      "(829 8290%) 3.0168\n",
      "(830 8300%) 2.2960\n",
      "(831 8310%) 5.9380\n",
      "(832 8320%) 4.7555\n",
      "(833 8330%) 3.0140\n",
      "(834 8340%) 0.9124\n",
      "(835 8350%) 6.8300\n",
      "(836 8360%) 2.3461\n",
      "(837 8370%) 2.5810\n",
      "(838 8380%) 4.0752\n",
      "(839 8390%) 3.3699\n",
      "(840 8400%) 3.2453\n",
      "(841 8410%) 1.4774\n",
      "(842 8420%) 2.7417\n",
      "(843 8430%) 1.1580\n",
      "(844 8440%) 4.9844\n",
      "(845 8450%) 5.6506\n",
      "(846 8460%) 5.1236\n",
      "(847 8470%) 3.9320\n",
      "(848 8480%) 4.3702\n",
      "(849 8490%) 4.4216\n",
      "(850 8500%) 6.2106\n",
      "(851 8510%) 2.9564\n",
      "(852 8520%) 3.9072\n",
      "(853 8530%) 4.9957\n",
      "(854 8540%) 3.7464\n",
      "(855 8550%) 2.2657\n",
      "(856 8560%) 3.2035\n",
      "(857 8570%) 4.4796\n",
      "(858 8580%) 4.3141\n",
      "(859 8590%) 2.1664\n",
      "(860 8600%) 6.4033\n",
      "(861 8610%) 3.3228\n",
      "(862 8620%) 4.2456\n",
      "(863 8630%) 4.5317\n",
      "(864 8640%) 3.7598\n",
      "(865 8650%) 2.7789\n",
      "(866 8660%) 5.7930\n",
      "(867 8670%) 2.9396\n",
      "(868 8680%) 1.9242\n",
      "(869 8690%) 4.5286\n",
      "(870 8700%) 1.5416\n",
      "(871 8710%) 4.6725\n",
      "(872 8720%) 4.4981\n",
      "(873 8730%) 2.9960\n",
      "(874 8740%) 2.6844\n",
      "(875 8750%) 2.8118\n",
      "(876 8760%) 3.8506\n",
      "(877 8770%) 2.5259\n",
      "(878 8780%) 2.7148\n",
      "(879 8790%) 3.6405\n",
      "(880 8800%) 1.5530\n",
      "(881 8810%) 3.1391\n",
      "(882 8820%) 1.9213\n",
      "(883 8830%) 4.0698\n",
      "(884 8840%) 2.2137\n",
      "(885 8850%) 4.4922\n",
      "(886 8860%) 4.2562\n",
      "(887 8870%) 1.1027\n",
      "(888 8880%) 2.8725\n",
      "(889 8890%) 2.9921\n",
      "(890 8900%) 2.1795\n",
      "(891 8910%) 5.2772\n",
      "(892 8920%) 1.5078\n",
      "(893 8930%) 2.1069\n",
      "(894 8940%) 1.7157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(895 8950%) 2.3273\n",
      "(896 8960%) 2.0332\n",
      "(897 8970%) 2.3997\n",
      "(898 8980%) 4.1392\n",
      "(899 8990%) 1.6401\n",
      "(900 9000%) 3.3084\n",
      "(901 9010%) 2.1375\n",
      "(902 9020%) 1.0310\n",
      "(903 9030%) 3.6959\n",
      "(904 9040%) 2.8701\n",
      "(905 9050%) 2.0204\n",
      "(906 9060%) 3.8856\n",
      "(907 9070%) 4.8772\n",
      "(908 9080%) 3.2336\n",
      "(909 9090%) 1.0065\n",
      "(910 9100%) 2.8203\n",
      "(911 9110%) 6.7024\n",
      "(912 9120%) 4.3834\n",
      "(913 9130%) 5.5559\n",
      "(914 9140%) 3.9844\n",
      "(915 9150%) 4.4662\n",
      "(916 9160%) 1.2627\n",
      "(917 9170%) 1.8317\n",
      "(918 9180%) 2.9188\n",
      "(919 9190%) 2.0300\n",
      "(920 9200%) 2.3838\n",
      "(921 9210%) 4.1008\n",
      "(922 9220%) 4.0528\n",
      "(923 9230%) 4.3405\n",
      "(924 9240%) 4.5046\n",
      "(925 9250%) 2.3615\n",
      "(926 9260%) 3.2252\n",
      "(927 9270%) 2.0133\n",
      "(928 9280%) 2.0388\n",
      "(929 9290%) 2.2498\n",
      "(930 9300%) 2.5454\n",
      "(931 9310%) 2.5528\n",
      "(932 9320%) 2.5090\n",
      "(933 9330%) 2.5109\n",
      "(934 9340%) 2.2407\n",
      "(935 9350%) 3.1549\n",
      "(936 9360%) 3.5790\n",
      "(937 9370%) 1.5973\n",
      "(938 9380%) 3.2621\n",
      "(939 9390%) 2.3939\n",
      "(940 9400%) 4.7931\n",
      "(941 9410%) 3.3666\n",
      "(942 9420%) 4.1133\n",
      "(943 9430%) 4.9498\n",
      "(944 9440%) 5.9166\n",
      "(945 9450%) 2.9350\n",
      "(946 9460%) 2.1426\n",
      "(947 9470%) 1.9516\n",
      "(948 9480%) 1.3464\n",
      "(949 9490%) 2.4034\n",
      "(950 9500%) 2.9451\n",
      "(951 9510%) 1.1675\n",
      "(952 9520%) 4.6673\n",
      "(953 9530%) 3.7889\n",
      "(954 9540%) 1.8215\n",
      "(955 9550%) 1.8975\n",
      "(956 9560%) 4.2725\n",
      "(957 9570%) 4.0650\n",
      "(958 9580%) 4.5495\n",
      "(959 9590%) 4.4778\n",
      "(960 9600%) 2.0526\n",
      "(961 9610%) 3.6464\n",
      "(962 9620%) 4.0264\n",
      "(963 9630%) 1.9329\n",
      "(964 9640%) 4.5144\n",
      "(965 9650%) 2.4502\n",
      "(966 9660%) 1.1273\n",
      "(967 9670%) 4.0193\n",
      "(968 9680%) 3.5556\n",
      "(969 9690%) 2.6650\n",
      "(970 9700%) 2.0316\n",
      "(971 9710%) 2.5513\n",
      "(972 9720%) 2.1210\n",
      "(973 9730%) 3.6899\n",
      "(974 9740%) 3.6209\n",
      "(975 9750%) 1.3453\n",
      "(976 9760%) 1.7917\n",
      "(977 9770%) 4.0436\n",
      "(978 9780%) 1.3313\n",
      "(979 9790%) 1.9874\n",
      "(980 9800%) 6.0942\n",
      "(981 9810%) 2.5031\n",
      "(982 9820%) 1.2699\n",
      "(983 9830%) 1.0183\n",
      "(984 9840%) 3.8106\n",
      "(985 9850%) 5.8766\n",
      "(986 9860%) 4.2649\n",
      "(987 9870%) 6.1361\n",
      "(988 9880%) 4.6726\n",
      "(989 9890%) 4.0461\n",
      "(990 9900%) 2.5812\n",
      "(991 9910%) 3.7053\n",
      "(992 9920%) 3.0813\n",
      "(993 9930%) 2.7247\n",
      "(994 9940%) 3.5682\n",
      "(995 9950%) 0.8832\n",
      "(996 9960%) 0.9582\n",
      "(997 9970%) 2.8367\n",
      "(998 9980%) 3.9911\n",
      "(999 9990%) 5.7930\n"
     ]
    }
   ],
   "source": [
    "encoder = EncoderRNN(len(ds.input_vocab2index)+2, 30)\n",
    "attn_decoder1 = AttnDecoderRNN(30, len(ds.output_vocab2index)+2, dropout_p=0.1)\n",
    "\n",
    "encoder_optimizer = torch.optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder_optimizer = torch.optim.SGD(attn_decoder1.parameters(), lr=0.01)\n",
    "training_pairs = np.random.randint(0, len(ds.input_texts), size=10000)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "print_loss_total = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    input_tensor, target_tensor = tensorsFromSent(ds.input_texts[training_pairs[i]], ds.target_texts[training_pairs[i]], \\\n",
    "                                                  ds.input_vocab2index, ds.output_vocab2index)\n",
    "\n",
    "    loss = train(input_tensor, target_tensor, encoder,\n",
    "               attn_decoder1, encoder_optimizer, decoder_optimizer, criterion)\n",
    "    print_loss_total += loss\n",
    "    \n",
    "    print_loss_avg = print_loss_total / 1\n",
    "    print_loss_total = 0\n",
    "    print('(%d %d%%) %.4f' % (i, i / 10 * 100, print_loss_avg))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (causalml)",
   "language": "python",
   "name": "causalml-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
